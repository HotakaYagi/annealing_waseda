{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:50:31.332627Z",
     "start_time": "2019-11-26T13:50:30.092482Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import csv, pickle\n",
    "from datetime import timedelta, datetime\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "import pickle\n",
    "import ast\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "p = Path.cwd()\n",
    "path = p.parent.parent.parent\n",
    "sys.path.append(str(path))\n",
    "from src import utils\n",
    "from src import conflict\n",
    "from src import voyage\n",
    "from src import fda_wrapper as fjw\n",
    "from pyproj import Geod\n",
    "\n",
    "date = datetime.now()\n",
    "stamp = '{0:%Y_%m_%d}'.format(date)\n",
    "_folder = str(p) + '/result/run_' + stamp + '/'\n",
    "if os.path.exists(_folder):\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:50:31.404104Z",
     "start_time": "2019-11-26T13:50:31.334540Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyqubo import Array, Constraint, Placeholder, solve_qubo, Sum, Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T14:25:05.690547Z",
     "start_time": "2019-11-26T14:25:05.684536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[Binary(x[0][0]), Binary(x[0][1])],\n",
       "       [Binary(x[1][0]), Binary(x[1][1])],\n",
       "       [Binary(x[2][0]), Binary(x[2][1])]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Array.create('x', (3, 2), 'BINARY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:50:31.423086Z",
     "start_time": "2019-11-26T13:50:31.405060Z"
    }
   },
   "outputs": [],
   "source": [
    "# make QUBO\n",
    "def make_hami_model(Nf, Nd, klist):\n",
    "    x = Array.create('x', (Nf, Nd), 'BINARY')\n",
    "\n",
    "    f_encoding = 0\n",
    "    for i in range(Nf):\n",
    "        f_encoding += Constraint((Sum(0, Nd, lambda j: x[i, j]) - 1)**2, label='encoding_{}'.format(i))\n",
    "\n",
    "    f_delay = 0\n",
    "    for i in range(Nf):\n",
    "        f_delay += Constraint(Dd*Sum(0, Nd, lambda j: j*x[i, j]), label='delay_{}'.format(i))\n",
    "\n",
    "    f_conflict = 0\n",
    "    for k in range(len(klist)):\n",
    "        Ck = klist[k]\n",
    "    #     print(len(Ck.conflictsteps))\n",
    "        i = int(Ck.voyages[0].id)\n",
    "        j = int(Ck.voyages[1].id)\n",
    "        Bk = klist[k].get_bk(time_separation)\n",
    "        fk = 0\n",
    "        for p in range(Nd):\n",
    "            for q in range(Nd):\n",
    "                Dk = Dd*(p-q)\n",
    "                if Dk >= Bk[0] and Dk <= Bk[1]:\n",
    "                    fk += x[i][p]*x[j][q]\n",
    "                else:\n",
    "                    pass\n",
    "        if fk != 0:\n",
    "            f_conflict += Constraint(fk, label='conflict_{}'.format(k))\n",
    "\n",
    "    # Define hamiltonian H\n",
    "    L_enc = Placeholder('L_enc')\n",
    "    L_del = Placeholder('L_del')\n",
    "    L_cof = Placeholder('L_cof')\n",
    "\n",
    "    H = L_enc * f_encoding + L_del*f_delay + L_cof * f_conflict\n",
    "    # Compile model\n",
    "    model = H.compile()\n",
    "    return model\n",
    "\n",
    "def make_hami_model_nocon(Nf, Nd, klist):\n",
    "    x = Array.create('x', (Nf, Nd), 'BINARY')\n",
    "\n",
    "    f_encoding = 0\n",
    "    for i in range(Nf):\n",
    "        f_encoding += (Sum(0, Nd, lambda j: x[i, j]) - 1)**2\n",
    "\n",
    "    f_delay = 0\n",
    "    for i in range(Nf):\n",
    "        f_delay += Dd*Sum(0, Nd, lambda j: j*x[i, j])\n",
    "\n",
    "    f_conflict = 0\n",
    "    for k in range(len(klist)):\n",
    "        Ck = klist[k]\n",
    "    #     print(len(Ck.conflictsteps))\n",
    "        i = int(Ck.voyages[0].id)\n",
    "        j = int(Ck.voyages[1].id)\n",
    "        Bk = klist[k].get_bk(time_separation)\n",
    "        fk = 0\n",
    "        for p in range(Nd):\n",
    "            for q in range(Nd):\n",
    "                Dk = Dd*(p-q)\n",
    "                if Dk >= Bk[0] and Dk <= Bk[1]:\n",
    "                    fk += x[i][p]*x[j][q]\n",
    "                else:\n",
    "                    pass\n",
    "        if fk != 0:\n",
    "            f_conflict += fk\n",
    "\n",
    "    # Define hamiltonian H\n",
    "    L_enc = Placeholder('L_enc')\n",
    "    L_del = Placeholder('L_del')\n",
    "    L_cof = Placeholder('L_cof')\n",
    "\n",
    "    H = L_enc * f_encoding + L_del*f_delay + L_cof * f_conflict\n",
    "    # Compile model\n",
    "    model = H.compile()\n",
    "    return model\n",
    "\n",
    "def decode_DA(model, Nf, Nd, result, Le, Lc, Nsol):\n",
    "    L_enc_ratio, L_cof_ratio = Le, Lc\n",
    "    sol_matDA = np.zeros([len(L_enc_ratio), len(L_cof_ratio), Nsol, 4])\n",
    "    for p in tqdm(range(len(L_enc_ratio))):\n",
    "        res_list = list()\n",
    "        for q in tqdm(range(len(L_cof_ratio))):\n",
    "            feed_dict = {'L_enc': L_enc_ratio[p], 'L_del':0.1, 'L_cof':L_cof_ratio[q]}\n",
    "            response = result[p][q]\n",
    "            for i in range(len(response)):\n",
    "                # Obtain the optimal solution\n",
    "                solution = response[i]\n",
    "\n",
    "                # Decode solution\n",
    "                decoded_solution, broken, energy = model.decode_solution(solution, vartype=\"BINARY\", feed_dict=feed_dict)\n",
    "#                 broken_list.append(broken)\n",
    "                Ndelay, Nenc = 0, 0\n",
    "                for j in range(Nf):\n",
    "                    Ndelay += 'delay_{}'.format(j) in broken\n",
    "                    Nenc += 'encoding_{}'.format(j) in broken\n",
    "#                     d = decoded_solution['x'][j]\n",
    "#                     for k in range(Nd):\n",
    "#                         if d[k] == 1:\n",
    "#                             delay += Dd * k\n",
    "                sol_matDA[p][q][i] = Nenc, len(broken)-Ndelay-Nenc, Ndelay, energy\n",
    "    return sol_matDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:50:42.659624Z",
     "start_time": "2019-11-26T13:50:31.425061Z"
    }
   },
   "outputs": [],
   "source": [
    "dd = '030'\n",
    "inc = '_1' #  ['_8', '_9']\n",
    "\n",
    "# exp_path = 'C:\\\\Users\\\\sho60\\\\OneDrive\\\\Documents\\\\github\\\\annealing_for_ships\\\\\\\n",
    "# data\\\\csv\\\\30x10_3Dd_5pattern_sep02\\\\csv_30x10_Dd' + dd + '\\\\20191125' + inc\n",
    "exp_path = 'C:\\\\Users\\\\sho60\\\\OneDrive\\\\Documents\\\\github\\\\annealing_for_ships\\\\data\\\\csv\\\\20191126_2'\n",
    "exppath = Path(exp_path)\n",
    "exp_m = utils.ExpManager(None, exppath)\n",
    "klist = exp_m.read_klist()\n",
    "\n",
    "Nf = len(exp_m.param['v_ids'])\n",
    "Nd = exp_m.param['Nd']\n",
    "Dd = exp_m.param['Dd'] # hour\n",
    "voyages = Nf\n",
    "\n",
    "separation = exp_m.param['sep'] # km\n",
    "time_separation = exp_m.param['t_sep'] # h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:50:48.986488Z",
     "start_time": "2019-11-26T13:50:42.661623Z"
    }
   },
   "outputs": [],
   "source": [
    "model = make_hami_model(Nf, Nd, klist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:50:56.053134Z",
     "start_time": "2019-11-26T13:50:48.988057Z"
    }
   },
   "outputs": [],
   "source": [
    "_model = make_hami_model_nocon(Nf, Nd, klist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:50:56.060041Z",
     "start_time": "2019-11-26T13:50:56.054999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5764"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(klist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solve QUBO\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve with SA in PyQUBO\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:51:13.759400Z",
     "start_time": "2019-11-26T13:50:56.062370Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Broken constarint : Enc=0, Conf=0, Delay=23\n",
      "#Broken constarint : Enc=0, Conf=0, Delay=25\n",
      "#Broken constarint : Enc=0, Conf=0, Delay=24\n"
     ]
    }
   ],
   "source": [
    "# Create QUBO \n",
    "feed_dict = {'L_enc': 35.0, 'L_del': 0.00, 'L_cof': 3.7}\n",
    "qubo, offset = model.to_qubo(feed_dict=feed_dict)\n",
    "\n",
    "num_sol = 3\n",
    "total_delay = 0\n",
    "broken_list = []\n",
    "slist = []\n",
    "sol_array = np.zeros([num_sol, 3])\n",
    "for i in range(num_sol):\n",
    "    # Solve the QUBO and obtain the optimal solution\n",
    "    solution = solve_qubo(qubo, 300)\n",
    "\n",
    "    # Decode solution\n",
    "    decoded_solution, broken, energy = model.decode_solution(solution, vartype=\"BINARY\", feed_dict=feed_dict)\n",
    "    broken_list.append(broken)\n",
    "    delay, Ndelay, Nenc = 0, 0, 0\n",
    "    dlist = []\n",
    "    for j in range(Nf):\n",
    "        Ndelay += 'delay_{}'.format(j) in broken\n",
    "        Nenc += 'encoding_{}'.format(j) in broken\n",
    "        d = decoded_solution['x'][j]\n",
    "        for k in range(Nd):\n",
    "            if d[k] == 1:\n",
    "                delay += Dd * k\n",
    "        dlist.append(delay)\n",
    "        total_delay += delay\n",
    "#     print(Ndelay)\n",
    "    slist.append(dlist)\n",
    "    sol_array[i] = [Nenc, len(broken)-Ndelay-Nenc, Ndelay]\n",
    "    print(\"#Broken constarint : Enc={}, Conf={}, Delay={}\".format(Nenc, len(broken)-Ndelay-Nenc, Ndelay))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine spec analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:52:25.150060Z",
     "start_time": "2019-11-26T13:52:25.143063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create QUBO\n",
    "_n_ = 4\n",
    "_nSol = 200\n",
    "L_enc_ratio = np.linspace(50, 350, _n_)\n",
    "L_cof_ratio = np.linspace(50, 250, _n_)\n",
    "# L_enc_ratio = np.linspace(10, 50, _n_)\n",
    "# L_cof_ratio = np.linspace(5, 25, _n_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital annealer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T13:52:25.160021Z",
     "start_time": "2019-11-26T13:52:25.153023Z"
    }
   },
   "outputs": [],
   "source": [
    "access_key = '6oKtgnFL9d41o4VwJYe4JxLFDdsHe3jA'\n",
    "proxies = {}\n",
    "\"\"\"\n",
    "    Doc P35参照\n",
    "    anneal_arg = {\n",
    "        \"expert_mode\": True,\n",
    "        \"noise_model\": \"METROPOLIS\",\n",
    "        \"number_iterations\": int32,\n",
    "        \"number_runs\": int32 16~128,\n",
    "        \"offset_increase_rate\": float 0 ~ 2000000000,\n",
    "        \"temperature_decay\": float,\n",
    "        \"temperature_interval\": int32 >1,\n",
    "        \"temperature_mode\": \"EXPONENTIAL\",\n",
    "        \"temperature_start\": float >0,\n",
    "        \"solution_mode\": \"COMPLETE\",\n",
    "        \"guidance_config\": ,\n",
    "    }\n",
    "\"\"\"\n",
    "anneal_arg = {\n",
    "        \"expert_mode\": True,\n",
    "        \"noise_model\": \"METROPOLIS\",\n",
    "        \"number_iterations\": int(200),\n",
    "        \"number_runs\": int(128),\n",
    "        \"offset_increase_rate\": int(1e2),\n",
    "        \"temperature_decay\": 1e-3,\n",
    "        \"temperature_interval\": int(50),\n",
    "        \"temperature_mode\": \"INVERSE_ROOT\",\n",
    "        \"temperature_start\": 10,\n",
    "        \"solution_mode\": \"COMPLETE\"\n",
    "    } # INVERSE_ROOT, INVERSE\n",
    "solver = fjw.DASolver(anneal_arg)\n",
    "# solver = fjw.DAPTSolver()\n",
    "solver.access_key = access_key\n",
    "solver.proxies = proxies"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T06:51:11.676730Z",
     "start_time": "2019-11-25T06:51:07.641252Z"
    }
   },
   "source": [
    "feed_dict = {'L_enc': L_enc_ratio[1], 'L_del':0.1, 'L_cof':L_cof_ratio[1]}\n",
    "qubo, offset = model.to_qubo(feed_dict=feed_dict)\n",
    "fuji_dic = fjw.PyQdic_to_FdicDA(qubo, offset, (Nf, Nd), anneal_arg)\n",
    "# fuji_dic = fjw.PyQdic_to_Fdic(qubo, offset, (Nf, Nd))\n",
    "response = solver.minimize(fuji_dic).get_solution_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T14:01:58.981636Z",
     "start_time": "2019-11-26T13:52:25.176020Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shota\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cedbfbc1c524818b468449eb12106d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shota\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d03044f98c404ba65f1bcbfde1a58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca230d82048450c8106e6c0c5a364b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_DA = datetime.now()\n",
    "stamp_DA = '{0:%H%M%S}'.format(date_DA)\n",
    "\n",
    "sol_matDA = np.zeros([len(L_enc_ratio), len(L_enc_ratio), _nSol, 4])\n",
    "aceMatnumDA = np.zeros([_n_, _n_])\n",
    "for p in tqdm(range(len(L_enc_ratio))):\n",
    "    for q in tqdm(range(len(L_cof_ratio))):\n",
    "        feed_dict = {'L_enc': L_enc_ratio[p], 'L_del':0.1, 'L_cof':L_cof_ratio[q]}\n",
    "        qubo, offset = model.to_qubo(feed_dict=feed_dict)\n",
    "        fuji_dic = fjw.PyQdic_to_FdicDA(qubo, offset, (Nf, Nd), anneal_arg)\n",
    "        flag = 0\n",
    "        while flag == 0:\n",
    "            try:\n",
    "                response = solver.minimize(fuji_dic).get_solution_list()\n",
    "                flag = 1\n",
    "            except:\n",
    "                print(\"error!!\")\n",
    "                pass\n",
    "        broken_list = []\n",
    "        ok = 0\n",
    "        for i in range(len(response)):\n",
    "            # Obtain the optimal solution\n",
    "            res = response[i].configuration\n",
    "            solution = fjw.Fres_to_PyQres(res, (Nf, Nd))\n",
    "\n",
    "            # Decode solution\n",
    "            decoded_solution, broken, energy = model.decode_solution(solution, vartype=\"BINARY\", feed_dict=feed_dict)\n",
    "            broken_list.append(broken)\n",
    "            delay, Ndelay, Nenc = 0, 0, 0\n",
    "            for j in range(Nf):\n",
    "                Ndelay += 'delay_{}'.format(j) in broken\n",
    "                Nenc += 'encoding_{}'.format(j) in broken\n",
    "                d = decoded_solution['x'][j]\n",
    "                for k in range(Nd):\n",
    "                    if d[k] == 1:\n",
    "                        delay += Dd * k\n",
    "            Nconf = int(len(broken)-Ndelay-Nenc)\n",
    "            sol_matDA[p][q][i] = Nenc, Nconf, Ndelay, energy\n",
    "            if int(Nenc) == 0 and Nconf == 0:\n",
    "                ok += 1\n",
    "        aceMatnumDA[p, q] = ok"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T07:17:55.663257Z",
     "start_time": "2019-11-21T07:17:55.652230Z"
    }
   },
   "source": [
    "np.save(folder+'solMat_DA'+stamp_DA+'.npy', sol_matDA)\n",
    "sol_matDA = np.load(folder+'solMat_DA'+stamp_DA+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T14:01:58.991606Z",
     "start_time": "2019-11-26T14:01:58.983604Z"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = L_enc_ratio, L_cof_ratio\n",
    "encMatAve_DA = np.sum(sol_matDA, axis=2)[:,:,0]/_nSol\n",
    "\n",
    "encMatAve_DA = np.sum(sol_matDA, axis=2)[:,:,0]/_nSol\n",
    "cofMatAve_DA = np.sum(sol_matDA, axis=2)[:,:,1]/_nSol\n",
    "delMatAve_DA = np.sum(sol_matDA, axis=2)[:,:,2]/_nSol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T14:01:59.925360Z",
     "start_time": "2019-11-26T14:01:58.993840Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=150)\n",
    "# plt.title('Encoding Error, $N_{sol}=100, \\lambda_d = 1$')\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "    \n",
    "\n",
    "a1 = ax1.contourf(X, Y, encMatAve_DA)\n",
    "# ax1.set_xlabel(r'$\\lambda_{conf}$')\n",
    "ax1.set_ylabel(r'$\\lambda_{enc}$')\n",
    "ax1.set_title('Encoding')\n",
    "ax1.tick_params(labelbottom=\"off\",bottom=\"off\") # x軸の削除\n",
    "# ax1.tick_params(labelleft=\"off\",left=\"off\") # y軸の削除\n",
    "\n",
    "a2 = ax2.contourf(X, Y, cofMatAve_DA)\n",
    "# ax2.set_xlabel(r'$\\lambda_{conf}$')\n",
    "# ax2.set_ylabel(r'$\\lambda_{enc}$')\n",
    "ax2.set_title('Conflict')\n",
    "ax2.tick_params(labelbottom=\"off\",bottom=\"off\") # x軸の削除\n",
    "ax2.tick_params(labelleft=\"off\",left=\"off\") # y軸の削除\n",
    "\n",
    "a3 = ax3.contourf(X, Y, delMatAve_DA)\n",
    "ax3.set_xlabel(r'$\\lambda_{conf}$')\n",
    "ax3.set_ylabel(r'$\\lambda_{enc}$')\n",
    "ax3.set_title('Delay')\n",
    "# ax3.tick_params(labelbottom=\"off\",bottom=\"off\") # x軸の削除\n",
    "# ax3.tick_params(labelleft=\"off\",left=\"off\") # y軸の削除\n",
    "\n",
    "# a4 = ax4.contourf(X, Y, (encMatAve_DA+cofMatAve_DA)/2)\n",
    "# ax4.set_xlabel(r'$\\lambda_{conf}$')\n",
    "# # ax4.set_ylabel(r'$\\lambda_{enc}$')\n",
    "# ax4.set_title('Total = (Err_enc + Err_conf)/2')\n",
    "# # ax4.tick_params(labelbottom=\"off\",bottom=\"off\") # x軸の削除\n",
    "# ax4.tick_params(labelleft=\"off\",left=\"off\") # y軸の削除\n",
    "\n",
    "a4 = ax4.contourf(X, Y, aceMatnumDA)\n",
    "ax4.set_xlabel(r'$\\lambda_{conf}$')\n",
    "ax4.set_title('# acceptable sols')\n",
    "ax4.tick_params(labelleft=\"off\",left=\"off\") # y軸の削除\n",
    "\n",
    "fig.colorbar(a1, ax=ax1)\n",
    "fig.colorbar(a2, ax=ax2)\n",
    "fig.colorbar(a3, ax=ax3)\n",
    "fig.colorbar(a4, ax=ax4)\n",
    "\n",
    "# ax1.grid()\n",
    "plt.tight_layout()\n",
    "fig.suptitle('{}'.format('Digital annealer')+' : Errors, $N_{sol}='+'{},'.format(_nSol)+' \\lambda_d = 0.1$')\n",
    "plt.subplots_adjust(top=.87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.679px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
